# Virtual Mouse â€“ Hand & Head Gesture Based HCI System

## Overview

This project implements an advanced **Humanâ€“Computer Interaction (HCI) Virtual Mouse system** that allows users to control the mouse cursor **without any physical device**, using only a standard webcam.

The system supports **two independent control modes**:

* **Hand Mouse** â€“ gesture-based mouse control using hand landmarks
* **Head Mouse** â€“ face, eye, mouth, and noseâ€“based mouse control

Both modes are integrated into a **single desktop GUI application**, making it easy to launch, switch, and use.

---

## Key Features

### ðŸ–ï¸ Hand Mouse

* Relative (velocity-based) cursor movement using wrist position
* Dead-zone based stabilization for precise control
* Gesture-based actions:

  * Index + Thumb pinch â†’ Left Click
  * Middle + Thumb pinch â†’ Right Click
  * Peace sign â†’ Toggle Scroll Mode
  * Fist â†’ Cursor Lock / Unlock
  * Thumb + Pinky â†’ Volume Control

### ðŸ‘¤ Head Mouse

* Relative nose-based cursor control (velocity-based)
* Mouth-open detection to activate cursor movement
* Eye gestures:

  * Left Wink â†’ Left Click
  * Right Wink â†’ Right Click
  * Blink â†’ Toggle Scroll Mode
* Automatic recalibration when mouth closes
* Optional absolute iris-tracking mode

### ðŸ–¥ï¸ GUI Application

* Single launcher for Hand Mouse and Head Mouse
* Detailed in-app usage guides
* Picture-in-Picture (PIP) camera mode
* Visual feedback (control circles, speed indicators)

---

## Project Structure

```
Virtual-Mouse/
â”‚
â”œâ”€â”€ calibrator/
â”‚   â”œâ”€â”€ calibratedconfig.py
â”‚   â”œâ”€â”€ calibrator.py
â”‚   â””â”€â”€ calibration_data_*.json
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ Snapshot.png
â”‚   â””â”€â”€ Virtual-Mouse.exe
â”‚
â”œâ”€â”€ hand_mouse.py        
â”œâ”€â”€ head_mouse.py        
â”œâ”€â”€ main.py              
â”œâ”€â”€ mouse_config.json    
â”œâ”€â”€ requirements.txt     
â”œâ”€â”€ project_setup.md
â””â”€â”€ README.md
```

---

## Execution Flow

1. **main.py** launches the GUI
2. User selects:

   * Hand Mouse â†’ runs `hand_mouse.py`
   * Head Mouse â†’ runs `head_mouse.py`
3. MediaPipe processes webcam input
4. Gestures are detected and mapped to mouse actions
5. PyAutoGUI performs system-level cursor actions

---
## ðŸ Miniconda Installation Guide

To install complex C packages (like dlib) easily, we use Miniconda.

- Download Miniconda from this Drive link:  [MiniConda](https://drive.google.com/file/d/1kT2CeuDSm7HL4M9swc4pMuRHg-AyMGU9/view?usp=drive_link) 

- Open the .exe file you just downloaded.

- Click "Next" on the welcome screen.

- Agree to the license agreement.

- For "Install for:", choose "Just Me" (this is the recommended and easiest option).

- Choose a destination folder (the default is usually fine).

###  Advanced Options (âš ï¸ Important):

- âŒ Do NOT check "Add Miniconda3 to my PATH environment variable." (This can conflict with other Python installs).

- âœ… DO check "Register Miniconda3 as my default Python 3.10" (or whichever version it shows).

- Click "Install" and let it finish.

## Running the Project (Source Code)

### Create Conda Environment

> conda create -n headmouse-env python=3.10.19

### Activate Conda Environment

> conda activate headmouse-env

### Install Dependencies

> pip install -r requirements.txt

### Run Application

> python main.py

---

## Executable (.exe) Version

For ease of use and deployment, the project has also been **packaged into a standalone Windows executable using PyInstaller**.

### Benefits

* No need to install Python or dependencies
* One-click execution
* Suitable for demonstrations and end users

### Build Command (used during development)

```
pyinstaller --noconfirm --onefile --windowed --collect-all mediapipe --collect-all cv2 --collect-all jax --name "Virtual-Mouse" main.py
```

The generated executable is available inside the `dist/` directory after build.

---

## System Requirements

* OS: Windows 10 / 11
* Camera: Any standard webcam
* RAM: Minimum 4 GB
* Python: 3.10.19 (for source-based execution)

---

## Technologies Used

* Python 3.10.19
* OpenCV
* MediaPipe (Hands & Face Mesh)
* PyAutoGUI
* NumPy
* Tkinter (GUI)
* PIL (Image handling)
* PyInstaller (Executable packaging)

---



## How It Works (Conceptual)

* Webcam feed is processed in real time
* MediaPipe extracts hand or facial landmarks
* Relative displacement from a reference point is calculated
* Velocity-based cursor movement is generated
* Gestures trigger mouse clicks, scrolling, and other actions

---

## Use Case

* Accessibility solutions
* Hands-free computer interaction
* Assistive technology
* HCI research & academic projects

---

## Support

If you face any issues during setup or execution, please raise an issue or contact the project maintainer.

---

